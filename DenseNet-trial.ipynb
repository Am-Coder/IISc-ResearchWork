{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:/games/IISc-May-2019/HAPT Data Set/FeatureSet/60feature_Dataset.csv\",header=None)\n",
    "# y = df.loc[:,200]    #for 200 features\n",
    "# X = df.loc[:,0:199]  \n",
    "\n",
    "# y = df.loc[:,100]    #for 100 features\n",
    "# X = df.loc[:,0:99]\n",
    "\n",
    "\n",
    "y = df.loc[:,60]      #for 60 features\n",
    "X = df.loc[:,0:59]\n",
    "# X.loc[:,:49] = X.loc[:,:49]*1e5        #Scaling \n",
    "# X.loc[:,100:149] = X.loc[:,100:149]*1e5    #Scaling\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uci_X = pd.read_csv(\"E:/games/IISc-May-2019/HAPT Data Set/Train/X_train.csv\")\n",
    "uci_y = pd.read_csv(\"E:/games/IISc-May-2019/HAPT Data Set/Train/y_train.csv\")\n",
    "# uci_X = uci_X.sample(frac=1).reset_index(drop=True)\n",
    "# uci_y = uci_y.sample(frac=1).reset_index(drop=True)\n",
    "uci_X = uci_X.loc[0:5000,:]\n",
    "uci_y = uci_y.loc[0:5000,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# One Hot Encoding of labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "label = LabelEncoder()\n",
    "intval = label.fit_transform(y)\n",
    "intval = intval.reshape(len(intval),1)\n",
    "onehot = OneHotEncoder(sparse = False)\n",
    "\n",
    "y = onehot.fit_transform(intval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5825, 200) (5825, 12)\n",
      "(243, 200) (243, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.96, shuffle=True) \n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', kernel_initializer = 'RandomUniform', input_dim = 200, name = \"layer-1\"))\n",
    "# model.add(Dense(32, activation = 'relu', kernel_initializer = 'uniform', name = \"layer-2\"))\n",
    "# model.add(Dense(32, activation = 'relu', kernel_initializer = 'uniform', name = \"layer-3\"))\n",
    "model.add(Dense(12,activation = 'softmax', kernel_initializer = 'uniform', name=\"Output-layer\"))\n",
    "optimizer = Adam(lr = 0.001)\n",
    "model.compile(  optimizer=optimizer ,\n",
    "                 loss='categorical_crossentropy', #Not binary as it is a multiclass problem\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer-1 (Dense)              (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "Output-layer (Dense)         (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 6,828\n",
      "Trainable params: 6,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000  0.905047  0.852541  0.816015  0.793414  0.779213  0.772652   \n",
      "1   0.905047  1.000000  0.953374  0.912814  0.899282  0.874884  0.865742   \n",
      "2   0.852541  0.953374  1.000000  0.970536  0.957875  0.936014  0.926624   \n",
      "3   0.816015  0.912814  0.970536  1.000000  0.985141  0.968339  0.959849   \n",
      "4   0.793414  0.899282  0.957875  0.985141  1.000000  0.984819  0.977373   \n",
      "5   0.779213  0.874884  0.936014  0.968339  0.984819  1.000000  0.992249   \n",
      "6   0.772652  0.865742  0.926624  0.959849  0.977373  0.992249  1.000000   \n",
      "7   0.757984  0.853192  0.916191  0.952814  0.970478  0.985734  0.994032   \n",
      "8   0.749480  0.843040  0.907003  0.947051  0.963999  0.978931  0.987390   \n",
      "9   0.745431  0.836516  0.902248  0.942963  0.959105  0.974589  0.984363   \n",
      "10  0.740900  0.836027  0.903306  0.941813  0.957855  0.973194  0.982566   \n",
      "11  0.732811  0.828696  0.897485  0.935533  0.954005  0.970568  0.979910   \n",
      "12  0.729221  0.823086  0.893864  0.931428  0.950372  0.967763  0.977846   \n",
      "13  0.724293  0.819651  0.890559  0.927115  0.947197  0.964381  0.974338   \n",
      "14  0.714826  0.811015  0.882586  0.922080  0.942164  0.960065  0.969950   \n",
      "15  0.568023  0.665881  0.706400  0.733728  0.754956  0.758731  0.766381   \n",
      "16  0.562718  0.656823  0.695328  0.722916  0.742589  0.744879  0.754234   \n",
      "17  0.579064  0.665491  0.699467  0.726122  0.744700  0.747304  0.754638   \n",
      "18  0.573825  0.660316  0.692200  0.713923  0.730984  0.730990  0.738896   \n",
      "19  0.556828  0.641751  0.673353  0.695211  0.711947  0.711999  0.719788   \n",
      "20  0.559113  0.643163  0.671461  0.689438  0.706355  0.705787  0.712686   \n",
      "21  0.548314  0.631178  0.660474  0.678143  0.695548  0.694631  0.701070   \n",
      "22  0.536650  0.617570  0.645281  0.662317  0.680602  0.680096  0.685826   \n",
      "23  0.532497  0.619660  0.646783  0.663076  0.682195  0.678424  0.683695   \n",
      "24  0.536634  0.622417  0.642893  0.653329  0.672349  0.667420  0.671236   \n",
      "25  0.522877  0.611554  0.629093  0.640308  0.661641  0.655627  0.661175   \n",
      "26  0.517209  0.606062  0.624619  0.633569  0.655081  0.646020  0.652740   \n",
      "27  0.503116  0.594022  0.610882  0.620935  0.642362  0.634503  0.642153   \n",
      "28  0.479827  0.567521  0.599231  0.608318  0.625305  0.623039  0.632181   \n",
      "29  0.418220  0.501111  0.533633  0.542627  0.559103  0.561503  0.569011   \n",
      "30  0.271226  0.361515  0.413602  0.426021  0.444702  0.467479  0.466453   \n",
      "31  0.322340  0.415486  0.481551  0.496123  0.519187  0.545612  0.544391   \n",
      "32  0.341344  0.417293  0.479357  0.500045  0.522856  0.549530  0.555312   \n",
      "33  0.355391  0.433711  0.498243  0.519805  0.546120  0.572373  0.578395   \n",
      "34  0.349182  0.434192  0.501394  0.522471  0.548628  0.576272  0.583014   \n",
      "35  0.355281  0.445747  0.513153  0.532298  0.557671  0.587583  0.594168   \n",
      "36  0.364189  0.452646  0.520616  0.538304  0.563945  0.593870  0.601667   \n",
      "37  0.363090  0.447478  0.514402  0.533457  0.559733  0.590434  0.601023   \n",
      "38  0.357071  0.443738  0.513398  0.531466  0.558751  0.589497  0.599424   \n",
      "39  0.356355  0.449639  0.518198  0.534397  0.562601  0.593780  0.602725   \n",
      "40  0.351572  0.441927  0.509700  0.526530  0.554587  0.586095  0.595497   \n",
      "41  0.357749  0.448626  0.516186  0.531799  0.560461  0.591903  0.601868   \n",
      "42  0.357836  0.452757  0.521687  0.537154  0.564825  0.596226  0.605669   \n",
      "43  0.357710  0.455182  0.524056  0.540180  0.568300  0.600794  0.610486   \n",
      "44  0.353337  0.451038  0.520717  0.537246  0.565741  0.597385  0.606397   \n",
      "45  0.492468  0.597927  0.666444  0.691154  0.718025  0.733863  0.743336   \n",
      "46  0.487565  0.593158  0.661970  0.686318  0.713205  0.729323  0.738778   \n",
      "47  0.486429  0.590496  0.660025  0.683851  0.710422  0.726351  0.735784   \n",
      "48  0.482943  0.588650  0.659482  0.684136  0.710790  0.726860  0.736296   \n",
      "49  0.476073  0.581282  0.650959  0.676515  0.701989  0.718163  0.727801   \n",
      "50  0.471932  0.574465  0.645396  0.672117  0.698035  0.714163  0.723988   \n",
      "51  0.459681  0.562062  0.631945  0.657483  0.683487  0.699830  0.710538   \n",
      "52  0.450528  0.553038  0.621673  0.646282  0.670932  0.686619  0.697424   \n",
      "53  0.447945  0.549832  0.618248  0.642354  0.666215  0.681478  0.692900   \n",
      "54  0.440103  0.539280  0.605394  0.629343  0.653226  0.668209  0.680120   \n",
      "55  0.437747  0.534051  0.597900  0.620868  0.646958  0.662625  0.675736   \n",
      "56  0.419039  0.512753  0.577144  0.600311  0.623962  0.639432  0.651310   \n",
      "57  0.412961  0.501458  0.565214  0.587386  0.614221  0.630236  0.641762   \n",
      "58  0.375701  0.468123  0.533108  0.555227  0.579342  0.593599  0.604101   \n",
      "59  0.346761  0.433170  0.503047  0.523658  0.545350  0.557145  0.567255   \n",
      "\n",
      "          7         8         9   ...        50        51        52        53  \\\n",
      "0   0.757984  0.749480  0.745431  ...  0.471932  0.459681  0.450528  0.447945   \n",
      "1   0.853192  0.843040  0.836516  ...  0.574465  0.562062  0.553038  0.549832   \n",
      "2   0.916191  0.907003  0.902248  ...  0.645396  0.631945  0.621673  0.618248   \n",
      "3   0.952814  0.947051  0.942963  ...  0.672117  0.657483  0.646282  0.642354   \n",
      "4   0.970478  0.963999  0.959105  ...  0.698035  0.683487  0.670932  0.666215   \n",
      "5   0.985734  0.978931  0.974589  ...  0.714163  0.699830  0.686619  0.681478   \n",
      "6   0.994032  0.987390  0.984363  ...  0.723988  0.710538  0.697424  0.692900   \n",
      "7   1.000000  0.995527  0.992810  ...  0.730413  0.716768  0.703514  0.698794   \n",
      "8   0.995527  1.000000  0.996318  ...  0.729077  0.714609  0.701378  0.696723   \n",
      "9   0.992810  0.996318  1.000000  ...  0.735935  0.721074  0.707305  0.702925   \n",
      "10  0.990382  0.993411  0.996630  ...  0.746270  0.731771  0.719224  0.714633   \n",
      "11  0.987012  0.989303  0.992990  ...  0.754392  0.740313  0.727721  0.722871   \n",
      "12  0.984312  0.986046  0.989879  ...  0.758250  0.743695  0.730763  0.725211   \n",
      "13  0.980551  0.982441  0.986475  ...  0.763649  0.749332  0.736527  0.730640   \n",
      "14  0.977820  0.981016  0.984907  ...  0.765565  0.751382  0.738765  0.732652   \n",
      "15  0.772577  0.775699  0.778528  ...  0.827112  0.819280  0.810705  0.808327   \n",
      "16  0.759800  0.763268  0.765998  ...  0.815119  0.806858  0.796836  0.795362   \n",
      "17  0.758966  0.761347  0.764230  ...  0.799829  0.790951  0.781038  0.779649   \n",
      "18  0.742204  0.744998  0.747509  ...  0.786939  0.778027  0.768504  0.767963   \n",
      "19  0.723419  0.727519  0.729997  ...  0.768860  0.760063  0.750504  0.751242   \n",
      "20  0.716020  0.719448  0.722302  ...  0.762841  0.753908  0.744761  0.745162   \n",
      "21  0.704687  0.708828  0.711586  ...  0.754650  0.746412  0.737508  0.737641   \n",
      "22  0.689231  0.692052  0.694002  ...  0.740869  0.734087  0.725884  0.725718   \n",
      "23  0.686719  0.689566  0.690626  ...  0.723828  0.717463  0.708976  0.709643   \n",
      "24  0.675262  0.678090  0.678555  ...  0.701565  0.695488  0.686583  0.687592   \n",
      "25  0.667772  0.670251  0.670096  ...  0.695659  0.690266  0.682091  0.681656   \n",
      "26  0.657201  0.659809  0.659558  ...  0.683032  0.678663  0.670349  0.670512   \n",
      "27  0.646731  0.648865  0.650366  ...  0.679449  0.675540  0.667404  0.668502   \n",
      "28  0.635699  0.638933  0.642796  ...  0.678983  0.675935  0.670083  0.670975   \n",
      "29  0.572424  0.576778  0.579462  ...  0.622176  0.618164  0.612442  0.613590   \n",
      "30  0.465075  0.466960  0.469107  ...  0.417258  0.408158  0.402312  0.397960   \n",
      "31  0.547734  0.547290  0.550812  ...  0.495471  0.486100  0.480390  0.477772   \n",
      "32  0.562841  0.562869  0.568898  ...  0.501243  0.494324  0.488279  0.483682   \n",
      "33  0.583033  0.579600  0.584578  ...  0.512519  0.505235  0.497114  0.492201   \n",
      "34  0.586512  0.584239  0.588419  ...  0.516955  0.509016  0.500876  0.497007   \n",
      "35  0.597426  0.596187  0.599213  ...  0.530106  0.521029  0.511818  0.507059   \n",
      "36  0.605267  0.604916  0.608680  ...  0.549004  0.539944  0.530172  0.524634   \n",
      "37  0.605190  0.604938  0.609951  ...  0.551787  0.544135  0.534901  0.529376   \n",
      "38  0.602807  0.602448  0.607881  ...  0.552556  0.545107  0.535533  0.529415   \n",
      "39  0.604856  0.603895  0.608885  ...  0.554928  0.546937  0.536357  0.529986   \n",
      "40  0.598604  0.598242  0.603550  ...  0.553040  0.545557  0.535374  0.528996   \n",
      "41  0.604988  0.603988  0.609809  ...  0.560186  0.552838  0.542631  0.536359   \n",
      "42  0.608679  0.607374  0.612990  ...  0.563229  0.555955  0.545579  0.539704   \n",
      "43  0.613427  0.611988  0.617756  ...  0.566404  0.558835  0.548077  0.541997   \n",
      "44  0.609446  0.608337  0.614303  ...  0.566018  0.558346  0.547265  0.541233   \n",
      "45  0.746685  0.744650  0.751125  ...  0.978535  0.969547  0.959254  0.949589   \n",
      "46  0.742292  0.740282  0.746603  ...  0.983253  0.975210  0.965188  0.955851   \n",
      "47  0.739509  0.737587  0.744074  ...  0.987731  0.979938  0.970408  0.961602   \n",
      "48  0.741077  0.739524  0.745899  ...  0.991020  0.982971  0.973418  0.964783   \n",
      "49  0.733319  0.731803  0.738739  ...  0.994934  0.988173  0.979540  0.971177   \n",
      "50  0.730413  0.729077  0.735935  ...  1.000000  0.993572  0.985129  0.976760   \n",
      "51  0.716768  0.714609  0.721074  ...  0.993572  1.000000  0.993916  0.987265   \n",
      "52  0.703514  0.701378  0.707305  ...  0.985129  0.993916  1.000000  0.994717   \n",
      "53  0.698794  0.696723  0.702925  ...  0.976760  0.987265  0.994717  1.000000   \n",
      "54  0.686354  0.684772  0.690254  ...  0.968409  0.978967  0.986309  0.992251   \n",
      "55  0.682550  0.680560  0.686737  ...  0.958918  0.969047  0.976678  0.983226   \n",
      "56  0.657977  0.656000  0.662579  ...  0.935965  0.947659  0.956384  0.963116   \n",
      "57  0.646721  0.644074  0.651309  ...  0.915221  0.927096  0.934137  0.941207   \n",
      "58  0.607939  0.605424  0.612921  ...  0.880342  0.892213  0.899463  0.906241   \n",
      "59  0.570885  0.568809  0.577460  ...  0.849535  0.858264  0.867889  0.875547   \n",
      "\n",
      "          54        55        56        57        58        59  \n",
      "0   0.440103  0.437747  0.419039  0.412961  0.375701  0.346761  \n",
      "1   0.539280  0.534051  0.512753  0.501458  0.468123  0.433170  \n",
      "2   0.605394  0.597900  0.577144  0.565214  0.533108  0.503047  \n",
      "3   0.629343  0.620868  0.600311  0.587386  0.555227  0.523658  \n",
      "4   0.653226  0.646958  0.623962  0.614221  0.579342  0.545350  \n",
      "5   0.668209  0.662625  0.639432  0.630236  0.593599  0.557145  \n",
      "6   0.680120  0.675736  0.651310  0.641762  0.604101  0.567255  \n",
      "7   0.686354  0.682550  0.657977  0.646721  0.607939  0.570885  \n",
      "8   0.684772  0.680560  0.656000  0.644074  0.605424  0.568809  \n",
      "9   0.690254  0.686737  0.662579  0.651309  0.612921  0.577460  \n",
      "10  0.701412  0.696976  0.672717  0.661443  0.623153  0.589825  \n",
      "11  0.709285  0.704970  0.680534  0.669294  0.630187  0.598312  \n",
      "12  0.712144  0.706970  0.681580  0.671094  0.630682  0.599454  \n",
      "13  0.717044  0.711690  0.686702  0.675898  0.635254  0.602757  \n",
      "14  0.719016  0.714241  0.689301  0.678886  0.638383  0.604927  \n",
      "15  0.800303  0.791447  0.763174  0.743237  0.698690  0.648527  \n",
      "16  0.788635  0.779353  0.751794  0.731979  0.689131  0.637180  \n",
      "17  0.772881  0.763495  0.736138  0.717008  0.674066  0.620798  \n",
      "18  0.760656  0.750403  0.721226  0.701229  0.659453  0.606202  \n",
      "19  0.744024  0.734755  0.707367  0.689468  0.646236  0.591641  \n",
      "20  0.737982  0.729150  0.701665  0.683639  0.640895  0.587647  \n",
      "21  0.731330  0.722878  0.695013  0.678075  0.636273  0.581357  \n",
      "22  0.719677  0.710192  0.681834  0.665373  0.624214  0.568190  \n",
      "23  0.703807  0.695976  0.669022  0.654052  0.614513  0.555024  \n",
      "24  0.679791  0.673742  0.650784  0.636376  0.601805  0.543284  \n",
      "25  0.674545  0.667668  0.644745  0.631343  0.596163  0.535774  \n",
      "26  0.665306  0.656081  0.630653  0.618627  0.580699  0.519662  \n",
      "27  0.663499  0.653589  0.625303  0.613018  0.575124  0.516186  \n",
      "28  0.663861  0.653779  0.627693  0.614524  0.581945  0.522188  \n",
      "29  0.608826  0.599438  0.574016  0.562445  0.537739  0.486567  \n",
      "30  0.389751  0.383263  0.372088  0.366038  0.349380  0.338133  \n",
      "31  0.468704  0.458402  0.451112  0.441906  0.416803  0.410868  \n",
      "32  0.473032  0.466534  0.454174  0.448091  0.423661  0.407891  \n",
      "33  0.480547  0.475337  0.462696  0.461017  0.435577  0.415780  \n",
      "34  0.484896  0.478580  0.464120  0.460694  0.436199  0.414343  \n",
      "35  0.495539  0.487981  0.473173  0.467912  0.443536  0.423985  \n",
      "36  0.512613  0.504815  0.489033  0.482143  0.456665  0.437317  \n",
      "37  0.517053  0.509270  0.491778  0.485661  0.460799  0.440395  \n",
      "38  0.517475  0.509393  0.492955  0.487451  0.462740  0.443396  \n",
      "39  0.517938  0.509792  0.492779  0.486544  0.460445  0.441582  \n",
      "40  0.517014  0.508773  0.490800  0.484487  0.459083  0.440435  \n",
      "41  0.524314  0.516115  0.497817  0.492001  0.464454  0.444228  \n",
      "42  0.527761  0.519648  0.501896  0.495980  0.468307  0.448503  \n",
      "43  0.529984  0.522729  0.504801  0.498998  0.470920  0.451400  \n",
      "44  0.529163  0.521374  0.503170  0.499023  0.470377  0.451168  \n",
      "45  0.940897  0.928800  0.904901  0.883106  0.847154  0.811811  \n",
      "46  0.946720  0.935249  0.912258  0.890952  0.855133  0.820564  \n",
      "47  0.952293  0.940388  0.916988  0.895901  0.861622  0.828235  \n",
      "48  0.956078  0.944480  0.920606  0.899184  0.864379  0.832758  \n",
      "49  0.962072  0.952558  0.929001  0.908563  0.874848  0.844480  \n",
      "50  0.968409  0.958918  0.935965  0.915221  0.880342  0.849535  \n",
      "51  0.978967  0.969047  0.947659  0.927096  0.892213  0.858264  \n",
      "52  0.986309  0.976678  0.956384  0.934137  0.899463  0.867889  \n",
      "53  0.992251  0.983226  0.963116  0.941207  0.906241  0.875547  \n",
      "54  1.000000  0.990085  0.969021  0.947239  0.909305  0.878287  \n",
      "55  0.990085  1.000000  0.982743  0.962663  0.924482  0.892468  \n",
      "56  0.969021  0.982743  1.000000  0.982134  0.947066  0.917343  \n",
      "57  0.947239  0.962663  0.982134  1.000000  0.961582  0.933186  \n",
      "58  0.909305  0.924482  0.947066  0.961582  1.000000  0.956454  \n",
      "59  0.878287  0.892468  0.917343  0.933186  0.956454  1.000000  \n",
      "\n",
      "[60 rows x 60 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dis = pd.DataFrame(X);\n",
    "print(dis.corr())\n",
    "plt.matshow(dis.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5825/5825 [==============================] - 1s 185us/step - loss: 5.5009 - acc: 0.3231\n",
      "Epoch 2/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 4.2218 - acc: 0.3478\n",
      "Epoch 3/100\n",
      "5825/5825 [==============================] - 0s 45us/step - loss: 2.7392 - acc: 0.4010\n",
      "Epoch 4/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.5679 - acc: 0.4328\n",
      "Epoch 5/100\n",
      "5825/5825 [==============================] - 0s 44us/step - loss: 2.3722 - acc: 0.4584\n",
      "Epoch 6/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3740 - acc: 0.4397\n",
      "Epoch 7/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.6847 - acc: 0.4422\n",
      "Epoch 8/100\n",
      "5825/5825 [==============================] - 0s 66us/step - loss: 2.5579 - acc: 0.4647\n",
      "Epoch 9/100\n",
      "5825/5825 [==============================] - 0s 60us/step - loss: 2.5837 - acc: 0.4563\n",
      "Epoch 10/100\n",
      "5825/5825 [==============================] - 0s 66us/step - loss: 2.5831 - acc: 0.4534\n",
      "Epoch 11/100\n",
      "5825/5825 [==============================] - 0s 60us/step - loss: 2.5461 - acc: 0.4591\n",
      "Epoch 12/100\n",
      "5825/5825 [==============================] - 0s 73us/step - loss: 2.4775 - acc: 0.4716\n",
      "Epoch 13/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.4935 - acc: 0.4678\n",
      "Epoch 14/100\n",
      "5825/5825 [==============================] - 0s 51us/step - loss: 2.4992 - acc: 0.4628\n",
      "Epoch 15/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.4652 - acc: 0.4735\n",
      "Epoch 16/100\n",
      "5825/5825 [==============================] - 0s 45us/step - loss: 2.4258 - acc: 0.4754\n",
      "Epoch 17/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.4151 - acc: 0.4759\n",
      "Epoch 18/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.4445 - acc: 0.4738\n",
      "Epoch 19/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.4533 - acc: 0.4755\n",
      "Epoch 20/100\n",
      "5825/5825 [==============================] - 0s 76us/step - loss: 2.3854 - acc: 0.4841\n",
      "Epoch 21/100\n",
      "5825/5825 [==============================] - 0s 50us/step - loss: 2.4282 - acc: 0.4761\n",
      "Epoch 22/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.3671 - acc: 0.4864\n",
      "Epoch 23/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.4557 - acc: 0.4757\n",
      "Epoch 24/100\n",
      "5825/5825 [==============================] - 0s 69us/step - loss: 3.8637 - acc: 0.4000\n",
      "Epoch 25/100\n",
      "5825/5825 [==============================] - 0s 52us/step - loss: 3.6858 - acc: 0.4182\n",
      "Epoch 26/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 3.6771 - acc: 0.4189\n",
      "Epoch 27/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 3.6724 - acc: 0.4179\n",
      "Epoch 28/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.7927 - acc: 0.4568\n",
      "Epoch 29/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.3996 - acc: 0.4827\n",
      "Epoch 30/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3431 - acc: 0.4939\n",
      "Epoch 31/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3783 - acc: 0.4886\n",
      "Epoch 32/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.3570 - acc: 0.4917\n",
      "Epoch 33/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.3712 - acc: 0.4874\n",
      "Epoch 34/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.3634 - acc: 0.4884\n",
      "Epoch 35/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3385 - acc: 0.4955\n",
      "Epoch 36/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.3452 - acc: 0.4934\n",
      "Epoch 37/100\n",
      "5825/5825 [==============================] - 0s 50us/step - loss: 2.3641 - acc: 0.4913\n",
      "Epoch 38/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3591 - acc: 0.4920\n",
      "Epoch 39/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3687 - acc: 0.4961\n",
      "Epoch 40/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.3447 - acc: 0.4951\n",
      "Epoch 41/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.3205 - acc: 0.5013\n",
      "Epoch 42/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.3127 - acc: 0.5027\n",
      "Epoch 43/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.3277 - acc: 0.5004\n",
      "Epoch 44/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.3155 - acc: 0.4972\n",
      "Epoch 45/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.3248 - acc: 0.4991\n",
      "Epoch 46/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.3374 - acc: 0.4997\n",
      "Epoch 47/100\n",
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.4248 - acc: 0.4936\n",
      "Epoch 48/100\n",
      "5825/5825 [==============================] - 0s 50us/step - loss: 2.2902 - acc: 0.5039\n",
      "Epoch 49/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.4050 - acc: 0.4920\n",
      "Epoch 50/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.3753 - acc: 0.4955\n",
      "Epoch 51/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.2811 - acc: 0.5109\n",
      "Epoch 52/100\n",
      "5825/5825 [==============================] - 0s 50us/step - loss: 2.2699 - acc: 0.5107\n",
      "Epoch 53/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.2881 - acc: 0.5080\n",
      "Epoch 54/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.3015 - acc: 0.5080\n",
      "Epoch 55/100\n",
      "5825/5825 [==============================] - 0s 45us/step - loss: 2.2686 - acc: 0.5150\n",
      "Epoch 56/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.2885 - acc: 0.5078\n",
      "Epoch 57/100\n",
      "5825/5825 [==============================] - 0s 49us/step - loss: 2.2714 - acc: 0.5102\n",
      "Epoch 58/100\n",
      "5825/5825 [==============================] - 0s 66us/step - loss: 2.2614 - acc: 0.5114\n",
      "Epoch 59/100\n",
      "5825/5825 [==============================] - 0s 51us/step - loss: 2.2937 - acc: 0.5083\n",
      "Epoch 60/100\n",
      "5825/5825 [==============================] - 0s 83us/step - loss: 2.2696 - acc: 0.5131\n",
      "Epoch 61/100\n",
      "5825/5825 [==============================] - 0s 62us/step - loss: 2.2387 - acc: 0.5202\n",
      "Epoch 62/100\n",
      "5825/5825 [==============================] - 1s 86us/step - loss: 2.2873 - acc: 0.5166\n",
      "Epoch 63/100\n",
      "5825/5825 [==============================] - 0s 66us/step - loss: 2.2520 - acc: 0.5174\n",
      "Epoch 64/100\n",
      "5825/5825 [==============================] - 0s 64us/step - loss: 2.2289 - acc: 0.5227\n",
      "Epoch 65/100\n",
      "5825/5825 [==============================] - 0s 73us/step - loss: 2.2323 - acc: 0.5219\n",
      "Epoch 66/100\n",
      "5825/5825 [==============================] - 0s 56us/step - loss: 2.2287 - acc: 0.5226\n",
      "Epoch 67/100\n",
      "5825/5825 [==============================] - 0s 78us/step - loss: 2.2220 - acc: 0.5222\n",
      "Epoch 68/100\n",
      "5825/5825 [==============================] - 0s 60us/step - loss: 2.2058 - acc: 0.5234\n",
      "Epoch 69/100\n",
      "5825/5825 [==============================] - 0s 65us/step - loss: 2.2037 - acc: 0.5288\n",
      "Epoch 70/100\n",
      "5825/5825 [==============================] - 0s 64us/step - loss: 2.2436 - acc: 0.5190\n",
      "Epoch 71/100\n",
      "5825/5825 [==============================] - 0s 55us/step - loss: 2.1910 - acc: 0.5286\n",
      "Epoch 72/100\n",
      "5825/5825 [==============================] - 0s 51us/step - loss: 2.2285 - acc: 0.5205\n",
      "Epoch 73/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.2093 - acc: 0.5255\n",
      "Epoch 74/100\n",
      "5825/5825 [==============================] - 0s 57us/step - loss: 2.2042 - acc: 0.5282\n",
      "Epoch 75/100\n",
      "5825/5825 [==============================] - 0s 51us/step - loss: 2.2487 - acc: 0.5191\n",
      "Epoch 76/100\n",
      "5825/5825 [==============================] - 0s 50us/step - loss: 2.1893 - acc: 0.5264\n",
      "Epoch 77/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.1872 - acc: 0.5258\n",
      "Epoch 78/100\n",
      "5825/5825 [==============================] - 0s 60us/step - loss: 2.1822 - acc: 0.5264\n",
      "Epoch 79/100\n",
      "5825/5825 [==============================] - 0s 53us/step - loss: 2.1665 - acc: 0.5294\n",
      "Epoch 80/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.1840 - acc: 0.5250\n",
      "Epoch 81/100\n",
      "5825/5825 [==============================] - 0s 50us/step - loss: 2.2073 - acc: 0.5250\n",
      "Epoch 82/100\n",
      "5825/5825 [==============================] - 0s 52us/step - loss: 2.1970 - acc: 0.5257\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5825/5825 [==============================] - 0s 46us/step - loss: 2.1891 - acc: 0.5282\n",
      "Epoch 84/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.1855 - acc: 0.5264\n",
      "Epoch 85/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.1778 - acc: 0.5286\n",
      "Epoch 86/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.1617 - acc: 0.5308\n",
      "Epoch 87/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.1470 - acc: 0.5320\n",
      "Epoch 88/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.1726 - acc: 0.5305\n",
      "Epoch 89/100\n",
      "5825/5825 [==============================] - 0s 44us/step - loss: 2.1488 - acc: 0.5301\n",
      "Epoch 90/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.1504 - acc: 0.5330\n",
      "Epoch 91/100\n",
      "5825/5825 [==============================] - 0s 44us/step - loss: 2.1568 - acc: 0.5320\n",
      "Epoch 92/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.1451 - acc: 0.5339\n",
      "Epoch 93/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.2311 - acc: 0.5210\n",
      "Epoch 94/100\n",
      "5825/5825 [==============================] - 0s 47us/step - loss: 2.1814 - acc: 0.5276\n",
      "Epoch 95/100\n",
      "5825/5825 [==============================] - 0s 44us/step - loss: 2.1503 - acc: 0.5348\n",
      "Epoch 96/100\n",
      "5825/5825 [==============================] - 0s 43us/step - loss: 2.1328 - acc: 0.5373\n",
      "Epoch 97/100\n",
      "5825/5825 [==============================] - 0s 44us/step - loss: 2.1456 - acc: 0.5325\n",
      "Epoch 98/100\n",
      "5825/5825 [==============================] - 0s 48us/step - loss: 2.1877 - acc: 0.5293\n",
      "Epoch 99/100\n",
      "5825/5825 [==============================] - 0s 45us/step - loss: 2.1340 - acc: 0.5361\n",
      "Epoch 100/100\n",
      "5825/5825 [==============================] - 0s 44us/step - loss: 2.1631 - acc: 0.5320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df01c34d30>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.fit of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001DF6D5F5080>>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     For Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(np.argmax(y_test,1), np.argmax(y_pred,1))\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486/486 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2104052200974751, 0.9351851842040387]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "# model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5582/5582 [==============================] - 0s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19867919124355884, 0.9378358870370975]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
